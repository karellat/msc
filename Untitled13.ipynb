{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import DEFAULT_PATH, AUTOTUNE\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import numpy as np\n",
    "from prepare_encoder_dataset import get_encoder_dataset, DEFAULT_GENERATOR_ARGS\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_conv_model(input_shape=(5,5,5,1),\n",
    "                           conv_kernel=(5,5,5),\n",
    "                           conv_activation='relu',\n",
    "                           regularization='l2',\n",
    "                           conv_filters=8,\n",
    "                           dense_activation=None):\n",
    "    fc_nodes = np.prod(input_shape)\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(input_shape, name='Input'), \n",
    "    tf.keras.layers.Conv3D(conv_filters, (5,5,5),name='Encoder-Conv', activation=conv_activation, kernel_regularizer=regularization),\n",
    "    tf.keras.layers.Dense(fc_nodes,activation=dense_activation, name='Decoder'),\n",
    "    tf.keras.layers.Reshape(input_shape, name='output')\n",
    "    ])\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=168600.0), HTML(value='')), layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=42600.0), HTML(value='')), layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - 15s 6ms/step - loss: 0.0214 - mse: 0.0129 - val_loss: 0.0114 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0266 - mse: 0.0193 - val_loss: 0.0153 - val_mse: 0.0078\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0374 - mse: 0.0343 - val_loss: 0.0247 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0199 - mse: 0.0114 - val_loss: 0.0104 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0344 - mse: 0.0289 - val_loss: 0.0261 - val_mse: 0.0191\n",
      "2635/2635 [==============================] - 16s 6ms/step - loss: 0.0366 - mse: 0.0336 - val_loss: 0.0246 - val_mse: 0.0241\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0279 - mse: 0.0249 - val_loss: 0.0247 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0410 - mse: 0.0382 - val_loss: 0.0386 - val_mse: 0.0383\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0377 - mse: 0.0347 - val_loss: 0.0247 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0057 - mse: 0.0047 - val_loss: 0.0038 - val_mse: 0.0034\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0180 - mse: 0.0171 - val_loss: 0.0169 - val_mse: 0.0166\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0229 - mse: 0.0216 - val_loss: 0.0064 - val_mse: 0.0048\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0064 - mse: 0.0054 - val_loss: 0.0040 - val_mse: 0.0036\n",
      "2635/2635 [==============================] - 15s 6ms/step - loss: 0.0245 - mse: 0.0237 - val_loss: 0.0232 - val_mse: 0.0231\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0223 - mse: 0.0210 - val_loss: 0.0062 - val_mse: 0.0046\n",
      "2635/2635 [==============================] - 15s 6ms/step - loss: 0.0125 - mse: 0.0097 - val_loss: 0.0062 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0302 - mse: 0.0282 - val_loss: 0.0269 - val_mse: 0.0254\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0311 - mse: 0.0285 - val_loss: 0.0169 - val_mse: 0.0125\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0202 - mse: 0.0116 - val_loss: 0.0103 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0226 - mse: 0.0150 - val_loss: 0.0115 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0373 - mse: 0.0341 - val_loss: 0.0246 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0271 - mse: 0.0220 - val_loss: 0.0153 - val_mse: 0.0068\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0396 - mse: 0.0353 - val_loss: 0.0346 - val_mse: 0.0303\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0369 - mse: 0.0337 - val_loss: 0.0246 - val_mse: 0.0241\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0282 - mse: 0.0249 - val_loss: 0.0247 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0418 - mse: 0.0385 - val_loss: 0.0388 - val_mse: 0.0385\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0380 - mse: 0.0350 - val_loss: 0.0247 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0255 - mse: 0.0164 - val_loss: 0.0124 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0295 - mse: 0.0214 - val_loss: 0.0161 - val_mse: 0.0076\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0349 - mse: 0.0300 - val_loss: 0.0255 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0247 - mse: 0.0156 - val_loss: 0.0121 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0310 - mse: 0.0229 - val_loss: 0.0177 - val_mse: 0.0093\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0361 - mse: 0.0312 - val_loss: 0.0256 - val_mse: 0.0241\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0299 - mse: 0.0250 - val_loss: 0.0258 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0437 - mse: 0.0387 - val_loss: 0.0399 - val_mse: 0.0387\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0340 - mse: 0.0291 - val_loss: 0.0256 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 12s 5ms/step - loss: 0.0045 - mse: 0.0036 - val_loss: 0.0027 - val_mse: 0.0021\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0139 - mse: 0.0132 - val_loss: 0.0087 - val_mse: 0.0082\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0155 - mse: 0.0142 - val_loss: 0.0059 - val_mse: 0.0047\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0047 - mse: 0.0039 - val_loss: 0.0027 - val_mse: 0.0021\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0118 - mse: 0.0110 - val_loss: 0.0092 - val_mse: 0.0087\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0161 - mse: 0.0147 - val_loss: 0.0057 - val_mse: 0.0044\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0112 - mse: 0.0085 - val_loss: 0.0054 - val_mse: 0.0037\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0286 - mse: 0.0267 - val_loss: 0.0249 - val_mse: 0.0236\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0252 - mse: 0.0217 - val_loss: 0.0177 - val_mse: 0.0131\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0243 - mse: 0.0146 - val_loss: 0.0119 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0279 - mse: 0.0189 - val_loss: 0.0154 - val_mse: 0.0074\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0352 - mse: 0.0302 - val_loss: 0.0255 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0250 - mse: 0.0152 - val_loss: 0.0122 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0325 - mse: 0.0245 - val_loss: 0.0189 - val_mse: 0.0115\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0363 - mse: 0.0311 - val_loss: 0.0256 - val_mse: 0.0241\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0298 - mse: 0.0248 - val_loss: 0.0257 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0424 - mse: 0.0374 - val_loss: 0.0387 - val_mse: 0.0373\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0338 - mse: 0.0287 - val_loss: 0.0256 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0260 - mse: 0.0152 - val_loss: 0.0131 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0293 - mse: 0.0199 - val_loss: 0.0140 - val_mse: 0.0061\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0355 - mse: 0.0288 - val_loss: 0.0270 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0244 - mse: 0.0135 - val_loss: 0.0121 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0304 - mse: 0.0207 - val_loss: 0.0157 - val_mse: 0.0078\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0358 - mse: 0.0293 - val_loss: 0.0269 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0317 - mse: 0.0253 - val_loss: 0.0267 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0450 - mse: 0.0386 - val_loss: 0.0408 - val_mse: 0.0384\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0336 - mse: 0.0271 - val_loss: 0.0270 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0040 - mse: 0.0031 - val_loss: 0.0024 - val_mse: 0.0019\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0103 - mse: 0.0095 - val_loss: 0.0065 - val_mse: 0.0060\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0130 - mse: 0.0118 - val_loss: 0.0056 - val_mse: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0038 - mse: 0.0031 - val_loss: 0.0024 - val_mse: 0.0018\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0125 - mse: 0.0118 - val_loss: 0.0078 - val_mse: 0.0073\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0133 - mse: 0.0120 - val_loss: 0.0055 - val_mse: 0.0044\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0103 - mse: 0.0077 - val_loss: 0.0052 - val_mse: 0.0037\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0295 - mse: 0.0276 - val_loss: 0.0264 - val_mse: 0.0252\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0242 - mse: 0.0212 - val_loss: 0.0194 - val_mse: 0.0156\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0264 - mse: 0.0155 - val_loss: 0.0133 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0271 - mse: 0.0160 - val_loss: 0.0145 - val_mse: 0.0061\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0354 - mse: 0.0287 - val_loss: 0.0270 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0259 - mse: 0.0154 - val_loss: 0.0123 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0265 - mse: 0.0159 - val_loss: 0.0136 - val_mse: 0.0057\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0358 - mse: 0.0291 - val_loss: 0.0270 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0316 - mse: 0.0250 - val_loss: 0.0269 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0432 - mse: 0.0367 - val_loss: 0.0388 - val_mse: 0.0364\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0337 - mse: 0.0271 - val_loss: 0.0270 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0287 - mse: 0.0155 - val_loss: 0.0143 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0338 - mse: 0.0209 - val_loss: 0.0198 - val_mse: 0.0086\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0372 - mse: 0.0277 - val_loss: 0.0294 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0272 - mse: 0.0136 - val_loss: 0.0142 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0308 - mse: 0.0177 - val_loss: 0.0170 - val_mse: 0.0069\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0376 - mse: 0.0282 - val_loss: 0.0295 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0345 - mse: 0.0253 - val_loss: 0.0292 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0486 - mse: 0.0397 - val_loss: 0.0437 - val_mse: 0.0391\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0351 - mse: 0.0258 - val_loss: 0.0296 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0032 - mse: 0.0024 - val_loss: 0.0019 - val_mse: 0.0014\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0092 - mse: 0.0084 - val_loss: 0.0064 - val_mse: 0.0060\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0112 - mse: 0.0100 - val_loss: 0.0055 - val_mse: 0.0047\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0034 - mse: 0.0026 - val_loss: 0.0020 - val_mse: 0.0016\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0078 - mse: 0.0071 - val_loss: 0.0052 - val_mse: 0.0048\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0118 - mse: 0.0106 - val_loss: 0.0052 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0097 - mse: 0.0071 - val_loss: 0.0052 - val_mse: 0.0037\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0319 - mse: 0.0302 - val_loss: 0.0291 - val_mse: 0.0279\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0239 - mse: 0.0217 - val_loss: 0.0206 - val_mse: 0.0179\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0273 - mse: 0.0131 - val_loss: 0.0149 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0340 - mse: 0.0212 - val_loss: 0.0172 - val_mse: 0.0065\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0373 - mse: 0.0277 - val_loss: 0.0293 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0281 - mse: 0.0144 - val_loss: 0.0141 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0310 - mse: 0.0176 - val_loss: 0.0163 - val_mse: 0.0062\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0377 - mse: 0.0282 - val_loss: 0.0295 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0347 - mse: 0.0254 - val_loss: 0.0293 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0500 - mse: 0.0410 - val_loss: 0.0452 - val_mse: 0.0408\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0354 - mse: 0.0260 - val_loss: 0.0296 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0328 - mse: 0.0132 - val_loss: 0.0196 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0344 - mse: 0.0155 - val_loss: 0.0209 - val_mse: 0.0061\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0419 - mse: 0.0270 - val_loss: 0.0343 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0317 - mse: 0.0123 - val_loss: 0.0190 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0331 - mse: 0.0139 - val_loss: 0.0203 - val_mse: 0.0057\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0420 - mse: 0.0272 - val_loss: 0.0346 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0401 - mse: 0.0259 - val_loss: 0.0352 - val_mse: 0.0261\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0533 - mse: 0.0395 - val_loss: 0.0484 - val_mse: 0.0397\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0394 - mse: 0.0253 - val_loss: 0.0337 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0028 - mse: 0.0020 - val_loss: 0.0017 - val_mse: 0.0014\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0064 - mse: 0.0057 - val_loss: 0.0046 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0098 - mse: 0.0088 - val_loss: 0.0054 - val_mse: 0.0047\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0028 - mse: 0.0021 - val_loss: 0.0018 - val_mse: 0.0014\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0083 - mse: 0.0076 - val_loss: 0.0064 - val_mse: 0.0060\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0101 - mse: 0.0089 - val_loss: 0.0051 - val_mse: 0.0042\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0102 - mse: 0.0074 - val_loss: 0.0054 - val_mse: 0.0037\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0352 - mse: 0.0335 - val_loss: 0.0326 - val_mse: 0.0314\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0232 - mse: 0.0212 - val_loss: 0.0185 - val_mse: 0.0154\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0333 - mse: 0.0143 - val_loss: 0.0193 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0390 - mse: 0.0205 - val_loss: 0.0242 - val_mse: 0.0091\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0418 - mse: 0.0269 - val_loss: 0.0345 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0335 - mse: 0.0143 - val_loss: 0.0191 - val_mse: 0.0041\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0378 - mse: 0.0193 - val_loss: 0.0220 - val_mse: 0.0069\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0424 - mse: 0.0274 - val_loss: 0.0344 - val_mse: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0402 - mse: 0.0260 - val_loss: 0.0356 - val_mse: 0.0261\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0548 - mse: 0.0407 - val_loss: 0.0501 - val_mse: 0.0411\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0395 - mse: 0.0253 - val_loss: 0.0338 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0410 - mse: 0.0110 - val_loss: 0.0283 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0472 - mse: 0.0177 - val_loss: 0.0311 - val_mse: 0.0066\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0528 - mse: 0.0264 - val_loss: 0.0451 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0421 - mse: 0.0124 - val_loss: 0.0280 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0479 - mse: 0.0190 - val_loss: 0.0305 - val_mse: 0.0066\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0522 - mse: 0.0267 - val_loss: 0.0449 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0513 - mse: 0.0272 - val_loss: 0.0469 - val_mse: 0.0287\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0657 - mse: 0.0425 - val_loss: 0.0605 - val_mse: 0.0431\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0484 - mse: 0.0251 - val_loss: 0.0423 - val_mse: 0.0244\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0026 - mse: 0.0019 - val_loss: 0.0017 - val_mse: 0.0014\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0050 - mse: 0.0043 - val_loss: 0.0029 - val_mse: 0.0026\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0088 - mse: 0.0078 - val_loss: 0.0053 - val_mse: 0.0047\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0027 - mse: 0.0020 - val_loss: 0.0018 - val_mse: 0.0014\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0066 - mse: 0.0059 - val_loss: 0.0054 - val_mse: 0.0051\n",
      "   2/2635 [..............................] - ETA: 5:22 - loss: 0.2053 - mse: 0.1871WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.108622). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.108622). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0089 - mse: 0.0078 - val_loss: 0.0048 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0099 - mse: 0.0069 - val_loss: 0.0054 - val_mse: 0.0038\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0362 - mse: 0.0345 - val_loss: 0.0340 - val_mse: 0.0328\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0227 - mse: 0.0206 - val_loss: 0.0165 - val_mse: 0.0121\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0407 - mse: 0.0105 - val_loss: 0.0282 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0439 - mse: 0.0139 - val_loss: 0.0299 - val_mse: 0.0052\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0529 - mse: 0.0265 - val_loss: 0.0452 - val_mse: 0.0242\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0419 - mse: 0.0120 - val_loss: 0.0281 - val_mse: 0.0040\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0467 - mse: 0.0175 - val_loss: 0.0311 - val_mse: 0.0077\n",
      "2635/2635 [==============================] - 15s 6ms/step - loss: 0.0523 - mse: 0.0267 - val_loss: 0.0448 - val_mse: 0.0243\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0511 - mse: 0.0272 - val_loss: 0.0470 - val_mse: 0.0289\n",
      "2635/2635 [==============================] - 13s 5ms/step - loss: 0.0662 - mse: 0.0427 - val_loss: 0.0608 - val_mse: 0.0431\n",
      "2635/2635 [==============================] - 14s 5ms/step - loss: 0.0485 - mse: 0.0251 - val_loss: 0.0425 - val_mse: 0.0244\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "conv_filters = [2, 8, 16, 32, 64 ,128]\n",
    "regularization = ['l1', 'l2', 'l1_l2']\n",
    "conv_activation = [None, 'relu', 'sigmoid']\n",
    "dense_activation = [None, 'relu', 'sigmoid']\n",
    "\n",
    "\n",
    "train_ds, valid_ds = get_encoder_dataset(path=DEFAULT_PATH ,**DEFAULT_GENERATOR_ARGS)\n",
    "\n",
    "for f, r, c_a, d_a in product(conv_filters, regularization, conv_activation, dense_activation):\n",
    "    model_name = f'f{f}-r{r}-c_a{c_a}-d_a{d_a}'\n",
    "    model = autoencoder_conv_model(conv_filters=f, regularization=r, conv_activation=c_a,dense_activation=d_a)\n",
    "\n",
    "\n",
    "    logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS=50\n",
    "\n",
    "    LOG_DIR = f\n",
    "    \"encoder/logs/{model_name}\"\n",
    "    MODELS_DIR = LOG_DIR + \"/models\"\n",
    "\n",
    "    file_writer_cm = tf.summary.create_file_writer(LOG_DIR + '/cm')\n",
    "    file_writer = tf.summary.create_file_writer(LOG_DIR + \"/metrics\")\n",
    "    file_writer.set_as_default()\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR)\n",
    "    model_save_callback = tf.keras.callbacks.ModelCheckpoint(MODELS_DIR, save_best_only=True)\n",
    "    earlystopping_callback = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  metrics=['mse'])\n",
    "\n",
    "    model.fit(train_ds.batch(BATCH_SIZE),\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_ds.batch(BATCH_SIZE),\n",
    "                        callbacks=[tensorboard_callback],\n",
    "                        workers=40,\n",
    "                        use_multiprocessing=True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = model.get_layer(name=\"Encoder-Conv\")\n",
    "conv.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_weights = conv.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encode_model = tf.keras.Sequential([\n",
    "    trained_conv\n",
    "]) \n",
    "encode_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_conv = tf.keras.layers.Convolution3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_conv = tf.keras.layers.Convolution3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_conv.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo import payan_montana_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_conv = tf.keras.layers.Convolution3D(8, (5,5,5), activation= conv.get_config()['activation'], padding='same', trainable=False,name='Conv')\n",
    "encode_model = tf.keras.Sequential([tf.keras.Input((193, 229, 193, 1), name='Input'), trained_conv])\n",
    "encode_model.get_layer('Conv').set_weights(conv.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import nibabel as nib\n",
    "from nilearn.plotting import plot_anat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(get_random_img_path())\n",
    "plot_anat(numpy_to_nibabel(img.get_fdata()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_img = encode_model.predict(np.array([np.expand_dims(img.get_fdata(), -1)]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nibabel import Nifti2Image\n",
    "def numpy_to_nibabel(numpy_array):\n",
    "    return Nifti2Image(numpy_array, np.eye(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat(numpy_to_nibabel(predicted_img[:, :, :, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    img = plot_anat(numpy_to_nibabel(predicted_img[:,:,:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat(numpy_to_nibabel(predicted_img[:,:,:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_anat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
