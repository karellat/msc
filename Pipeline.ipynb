{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib \n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib \n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "from typing import Callable\n",
    "# TODO: Could be refactor as TFRecord class\n",
    "def nii_reader(path:str, default_shape:tuple=(256, 256, 166), ignore_shape:bool=True):\n",
    "    # TODO: Could be extended to multiple formats\n",
    "    # TODO: Could return objects of Nibel etc.\n",
    "    # TODO: Optimalize reading, test different methods \n",
    "    # https://simpleitk.readthedocs.io\n",
    "    # https://nipy.org/nibael/\n",
    "    # https://nilearn.github.io/\n",
    "    assert os.path.isfile(path)\n",
    "    img = nib.load(path)\n",
    "    if img.shape != default_shape:\n",
    "        logging.warning(f'Unexpected shape {img.shape}, default shape {default_shape}, file {path}')\n",
    "        if ignore_shape: return None \n",
    "    \n",
    "    return np.squeeze(np.array(img.get_fdata()))\n",
    "\n",
    "def nii_dir_generator(input_dir:str,\n",
    "                      fname2label: Callable[[str], str]=None,\n",
    "                      image_ext:str=\"nii\",\n",
    "                      default_shape:tuple=(256, 256, 166),\n",
    "                      ignore_shape:bool=False):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(input_dir):\n",
    "        for f in filenames:\n",
    "            if f.endswith(image_ext):\n",
    "                f_path = os.path.join(dirpath, f)\n",
    "                logging.info(f'Read nii file from {f_path}')\n",
    "                img = nii_reader(f_path, default_shape=default_shape, ignore_shape=ignore_shape)\n",
    "                if fname2label:\n",
    "                    yield fname2label(f), img\n",
    "                else:\n",
    "                    yield f, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# ADNI tools\n",
    "# TODO: Separate\n",
    "def parse_adni_img_id(adni_img_name):\n",
    "    assert adni_img_name.startswith(\"ADNI_\")\n",
    "    adni_id = re.findall(r\".*_I([0-9]+)\\.nii\", adni_img_name)\n",
    "    if len(adni_id) != 1:\n",
    "        logging.error(\"Unknown subject ID: {}\".format(adni_img_name))\n",
    "    return adni_id[0]\n",
    "\n",
    "def parse_adni_usr_id(adni_img_name):\n",
    "    assert adni_img_name.startswith(\"ADNI_\")\n",
    "    adni_id = re.findall(r\"ADNI_([0-9]+_S_[0-9]+)_\", adni_img_name)\n",
    "    if len(adni_id) != 1:\n",
    "        logging.error(\"Unknown subject ID: {}\".format(adni_img_name))\n",
    "    return adni_id[0]\n",
    "\n",
    "def get_adni_group(adni_img_name, adni_desc_df): \n",
    "    img_id = parse_adni_img_id(adni_img_name)\n",
    "    adni_ids = adni_desc_df.loc[adni_desc_df['Image Data ID']== 45108, 'Group'].values\n",
    "    assert adni_ids.shape[0] == 1\n",
    "    return adni_ids[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inplace method much more faster \n",
    "# TODO: Aware of diffrent scanners \n",
    "# MARK: Sklearn does not work od 3D data\n",
    "# TODO: Registration etc... https://mirtk.github.io\n",
    "# https://nilearn.github.io\n",
    "def normalize(data, feature_range=(0,1), method=\"MinMax\", min_data=None, max_data=None, copy=True):\n",
    "    min_out, max_out = feature_range\n",
    "    if method == \"MinMax\":\n",
    "        if not min_data: np.min(data)\n",
    "        if not max_data: np.max(data)\n",
    "            \n",
    "        scale = (max_out - min_out) / (max_data - min_data)\n",
    "        if copy: \n",
    "            return data * scale + min_out - min_data * scale\n",
    "        else: \n",
    "            data *= scale\n",
    "            data += min_out - min_data * scale\n",
    "    else:\n",
    "        raise Exception(\"Unknown method {}\".format(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_baseline():\n",
    "    img_inputs = layers.Input((256, 256, 166, 1))\n",
    "    conv0 = layers.Conv3D(16,\n",
    "                          3,\n",
    "                          strides=(2,2,2),\n",
    "                          activation='relu')(img_inputs)\n",
    "    conv1 = layers.Conv3D(32,\n",
    "                          3,\n",
    "                          strides=(2,2,2),\n",
    "                          activation='relu')(conv0)\n",
    "    conv2 = layers.Conv3D(64,\n",
    "                          3, \n",
    "                          strides=(2,2,2),\n",
    "                          activation='relu')(conv1)\n",
    "    conv3 = layers.Conv3D(128,\n",
    "                          3, \n",
    "                          strides=(2,2,2),\n",
    "                          activation='relu')(conv2)\n",
    "    conv4 = layers.Conv3D(256,\n",
    "                          3, \n",
    "                          strides=(2,2,2),\n",
    "                          activation='relu')(conv3)\n",
    "    flatten = layers.Flatten()(conv4)\n",
    "\n",
    "    output = layers.Dense(2, activation='softmax')(flatten)\n",
    "\n",
    "    return(tf.keras.Model(inputs=img_inputs, outputs=output, name='3D_Dense'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "# TODO: Move to config file\n",
    "# IMG\n",
    "# ADNI \n",
    "ADNI_DF = pd.read_csv(\"ADNI1_Complete_1Yr_1.5T_11_21_2019.csv\")\n",
    "# READING\n",
    "IMG_PATH = 'data'\n",
    "IMG_EXT = 'nii'\n",
    "IMG_SHAPE = (256, 256, 166)\n",
    "IMG_IGNORE_BAD_SHAPE = True\n",
    "FNAME_TO_LABEL = lambda x: get_adni_group(x, ADNI_DF)\n",
    "# NORMALIZATION\n",
    "NORM_METHOD = 'MinMax'\n",
    "NORM_RANGE = (0, 1)\n",
    "# AUGMENTATION \n",
    "\n",
    "# CLASS BALANCING\n",
    "\n",
    "# TRAINING\n",
    "T_BATCH_SIZE = 2\n",
    "T_EPOCHS = 10\n",
    "T_LOGS = 'logs'\n",
    "T_CHECKPOINT = 'checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "4/6 [===================>..........] - ETA: 3s - loss: 0.5495 - accuracy: 1.0000\n",
      "Epoch 00001: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 14s 2s/sample - loss: 0.3665 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4/6 [===================>..........] - ETA: 3s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00002: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 12s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00003: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 11s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00004: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 12s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/6 [===================>..........] - ETA: 3s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00005: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 12s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00006: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 11s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00007: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 11s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00008: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 12s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00009: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 11s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/6 [===================>..........] - ETA: 2s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 00010: saving model to checkpoints\n",
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 12s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Test\n",
      "2/1 [============================================================] - 2s 818ms/sample - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Test loss: 0.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from logging import info, warning, error\n",
    "# READ PHASE\n",
    "info(f'Reading from {IMG_PATH}')\n",
    "\n",
    "labels = []\n",
    "images = []\n",
    "img_generator = nii_dir_generator(input_dir=IMG_PATH,\n",
    "                                  fname2label=FNAME_TO_LABEL,\n",
    "                                  image_ext=IMG_EXT,\n",
    "                                  default_shape=IMG_SHAPE,\n",
    "                                  ignore_shape=IMG_IGNORE_BAD_SHAPE)\n",
    "for fname, img in img_generator:\n",
    "    labels.append(fname)\n",
    "    images.append(img)\n",
    "    \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "info('Reading finished')\n",
    "\n",
    "# NORMALIZATION PHASE\n",
    "voxel_mean = np.mean(images)\n",
    "voxel_std = np.std(images)\n",
    "voxel_max = np.max(images)\n",
    "voxel_min = np.min(images)\n",
    "\n",
    "normalize(images, \n",
    "          feature_range=(0,1),\n",
    "          method=NORM_METHOD, \n",
    "          min_data=voxel_min,\n",
    "          max_data=voxel_max, \n",
    "          copy=False)\n",
    "\n",
    "info('Normalization finished')\n",
    "\n",
    "# DATA AUGMENTATION PHASE\n",
    "# TODO: Implement\n",
    "\n",
    "#CLASS BALANCING PHASE \n",
    "# TODO: Implement \n",
    "\n",
    "#PREPARATION PHASE\n",
    "\n",
    "assert images.shape[-1] != 1\n",
    "\n",
    "images = images.reshape((*images.shape,1)).astype('float32')\n",
    "labels = labels == 'CN'\n",
    "\n",
    "train_x = images[2:]\n",
    "train_y = labels[2:]\n",
    "\n",
    "test_x = images[:2]\n",
    "test_y = labels[:2]\n",
    "\n",
    "val_x = test_x\n",
    "val_y = test_y\n",
    "\n",
    "info('Preparation finished')\n",
    "\n",
    "# TRAINING PHASE\n",
    "# TODO: USE Straka logging name trick \n",
    "callbacks = [tf.keras.callbacks.TensorBoard(log_dir=T_LOGS),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=T_CHECKPOINT, \n",
    "                                                verbose=1)\n",
    "            ]\n",
    "model = get_baseline()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=T_BATCH_SIZE,\n",
    "                    epochs=T_EPOCHS,\n",
    "                    validation_data=(val_x, val_y),\n",
    "                    callbacks=callbacks)\n",
    "# EVALUATE PHASE \n",
    "print(f'Test')\n",
    "test_scores = model.evaluate(test_x, test_y, batch_size=T_BATCH_SIZE)\n",
    "print(f'Test loss: {test_scores[0]}')\n",
    "print(f'Test accuracy: {test_scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tsaved_model.pb\tvariables\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
