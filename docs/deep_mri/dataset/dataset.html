<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>deep_mri.dataset.dataset API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>deep_mri.dataset.dataset</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import tensorflow as tf
import numpy as np
import random
import os
import glob
import logging
from nibabel import Nifti2Image
from auto_tqdm import tqdm
import pandas as pd
import re
from enum import Enum, auto

from deep_mri.dataset import DEFAULT_PATH, CLASS_NAMES, DEFAULT_CSV_PATH


def _get_label_tf(target_name, class_names):
    &#34;&#34;&#34;
    Creating tensor label.
    Parameters
    ----------
    target_name : str
        Name of the target class
    class_names
        Names of all the predicted groups
    Returns
    -------
    tf.Tensor
        Boolean tensor of len(class_names)
    &#34;&#34;&#34;
    return target_name == class_names


def _merge_items(dictionary):
    &#34;&#34;&#34;
    Merging all items of dictionary into the list.
    Parameters
    ----------
    dictionary : dict
        General dictionary

    Returns
    -------
    list
        Items of all keys merged.
    &#34;&#34;&#34;
    items = []
    for key in dictionary.keys():
        items += dictionary[key]
    return items


def load_files_to_dataset(files_list, items_count, generator, **gen_arguments):
    &#34;&#34;&#34;
    Creating tensorflow dataset from a generator.

    Parameters
    ----------
    files_list : list
        Image file paths
    items_count : int
        Number of outputs expected from generator(multiple output from single file)
    generator : iterable
        Generator returning the images as tensors
    gen_arguments : dict
        Dictionary of arguments for the Generator
    Returns
    -------
    tf.data.Dataset
        Tensorflow dataset of images and desired labels generated by generator
    &#34;&#34;&#34;
    input_arrays = []
    targets = []
    pbar = tqdm(total=items_count)
    gen = generator(files_list=files_list, **gen_arguments)
    for sample, target in gen:
        input_arrays.append(sample)
        targets.append(target)
        pbar.update(1)
    pbar.close()
    return tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(input_arrays), tf.convert_to_tensor(targets)))


def get_random_img_path(path=DEFAULT_PATH):
    &#34;&#34;&#34;
    Return random file from the given path
    Parameters
    ----------
    path: str

    Returns
    -------
    str
    &#34;&#34;&#34;
    files_list = glob.glob(path)
    return files_list[random.randint(0, len(files_list))]


def numpy_to_nibabel(numpy_array):
    &#34;&#34;&#34;
    Transform the numpy array into the `nibabel.Image` instance.
    Parameters
    ----------
    numpy_array: np.array
        3D array
    Returns
    -------
    nibabel.Image
        Represent each cell of the 3D array as a voxel
    &#34;&#34;&#34;
    return Nifti2Image(numpy_array, np.eye(4))


def _get_image_id(name):
    &#34;&#34;&#34;
    Transform the adni file name into the image id
    Parameters
    ----------
    name: str
        Path or name of adni file

    Returns
    -------
    int
        Id of the adni image

    &#34;&#34;&#34;
    return int(re.search(&#39;_image_id_([0-9]*)&#39;, name).group(1))


def _get_image_group(file_path, class_folder):
    parts = file_path.split(os.path.sep)
    assert np.sum(parts[class_folder] == CLASS_NAMES) == 1
    return CLASS_NAMES[np.argmax(parts[class_folder] == CLASS_NAMES)]


class ShuffleStrategy(Enum):
    SHUFFLE_RANDOM = auto()
    SHUFFLE_SUBJECTS = auto()


def get_train_valid_files(path=DEFAULT_PATH,
                          csv_path=DEFAULT_CSV_PATH,
                          train_filter_first_screen=True,
                          valid_filter_first_screen=False,
                          shuffle_strategy=ShuffleStrategy.SHUFFLE_SUBJECTS,
                          valid_train_ratio=0.2,
                          shuffle=False,
                          dropping_group=None,
                          im_id_fnc=_get_image_id,
                          group_folder=-3):
    if dropping_group is not None:
        assert dropping_group in CLASS_NAMES, f&#34;Unknown group to drop {dropping_group}&#34;
    assert isinstance(shuffle_strategy, ShuffleStrategy)

    files_list = glob.glob(path)
    # meta info
    df = pd.read_csv(csv_path)
    df = df.set_index(&#39;Image Data ID&#39;)
    df[&#39;Group&#39;] = df[&#39;Group&#39;].str.lower()
    meta_info = df[[&#39;Visit&#39;, &#39;Group&#39;, &#39;Subject&#39;]].to_dict(&#39;index&#39;)
    if shuffle_strategy == ShuffleStrategy.SHUFFLE_SUBJECTS:
        # Split into groups by subject id
        subjects = {c: [] for c in CLASS_NAMES}
        for f in files_list:
            image_id = int(im_id_fnc(f))
            target = _get_image_group(f, group_folder)
            assert target == meta_info[image_id][&#39;Group&#39;]
            subject = meta_info[image_id][&#39;Subject&#39;]
            visit = meta_info[image_id][&#39;Visit&#39;]
            if visit == 1:
                subjects[target].append(subject)

        # Shuffle
        rnd = random.Random(42)
        if shuffle:
            for group in subjects:
                rnd.shuffle(group)

        # Count groups
        groups_count = np.array([len(subjects[key]) for key in subjects.keys()])
        for count, group in zip(groups_count, subjects.keys()):
            logging.warning(f&#39;{group.upper()} count: {count}&#39;)

        # Split Subjects into train valid groups
        valid_sizes = np.ceil(groups_count * valid_train_ratio).astype(int)
        train_subjects = {key: subjects[key][valid_size:] for key, valid_size in zip(subjects.keys(), valid_sizes)}
        valid_subjects = {key: subjects[key][:valid_size] for key, valid_size in zip(subjects.keys(), valid_sizes)}

        # Groups changed after visits
        train_subjects = _merge_items(train_subjects)
        valid_subjects = _merge_items(valid_subjects)

        train_files = []
        valid_files = []
        for f in files_list:
            image_id = int(im_id_fnc(f))
            target = _get_image_group(f, group_folder)
            assert target == meta_info[image_id][&#39;Group&#39;]
            subject = meta_info[image_id][&#39;Subject&#39;]
            visit = meta_info[image_id][&#39;Visit&#39;]
            # Drop unwanted groups
            if target == dropping_group:
                continue
            if subject in train_subjects:
                if train_filter_first_screen and visit != 1:
                    continue
                train_files.append(f)
            elif subject in valid_subjects:
                if valid_filter_first_screen and visit != 1:
                    continue
                valid_files.append(f)
            else:
                assert visit != 1, &#34;None seen imgs&#34;
                logging.info(f&#34;Image {image_id} without first visit, subject {subject}&#34;)
                if not train_filter_first_screen:
                    logging.info(f&#34;{image_id} appending to train set&#34;)
                    train_files.append(f)

        train_targets = list(map(lambda x: _get_image_group(x, group_folder), train_files))
        valid_targets = list(map(lambda x: _get_image_group(x, group_folder), valid_files))

        return train_files, train_targets, valid_files, valid_targets
    else:
        # Split into groups by subject id
        groups = {c: [] for c in CLASS_NAMES}
        non_first_visit_files = []
        for f in files_list:
            image_id = int(im_id_fnc(f))
            target = _get_image_group(f, group_folder)
            if target == dropping_group:
                continue
            assert target == meta_info[image_id][&#39;Group&#39;]
            visit = meta_info[image_id][&#39;Visit&#39;]
            if (train_filter_first_screen or valid_filter_first_screen) and visit == 1:
                non_first_visit_files.append(f)
            else:
                groups[target].append(f)
        # Shuffle
        rnd = random.Random(42)
        if shuffle:
            for group in groups:
                rnd.shuffle(group)

        # Count groups
        groups_count = np.array([len(groups[key]) for key in groups.keys()])
        for count, group in zip(groups_count, groups.keys()):
            logging.warning(f&#39;{group.upper()} count: {count}&#39;)
        # Split files into train valid groups
        valid_sizes = np.ceil(groups_count * valid_train_ratio).astype(int)
        train_files = {key: groups[key][valid_size:] for key, valid_size in zip(groups.keys(), valid_sizes)}
        valid_files = {key: groups[key][:valid_size] for key, valid_size in zip(groups.keys(), valid_sizes)}

        train_files = _merge_items(train_files)
        valid_files = _merge_items(valid_files)

        if len(non_first_visit_files) &gt; 0:
            logging.warning(f&#39;Filtering non first visit count:{len(non_first_visit_files)}, appending to allowed set&#39;)
            if not train_filter_first_screen:
                train_files = train_files + non_first_visit_files
            if not valid_filter_first_screen:
                valid_files = valid_files + non_first_visit_files

        # Prepare targets
        train_targets = list(map(lambda x: _get_image_group(x, group_folder), train_files))
        valid_targets = list(map(lambda x: _get_image_group(x, group_folder), valid_files))

        return train_files, train_targets, valid_files, valid_targets</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="deep_mri.dataset.dataset.get_random_img_path"><code class="name flex">
<span>def <span class="ident">get_random_img_path</span></span>(<span>path='/ADNI/minc_beast/*/*/*.nii')</span>
</code></dt>
<dd>
<div class="desc"><p>Return random file from the given path
Parameters</p>
<hr>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_random_img_path(path=DEFAULT_PATH):
    &#34;&#34;&#34;
    Return random file from the given path
    Parameters
    ----------
    path: str

    Returns
    -------
    str
    &#34;&#34;&#34;
    files_list = glob.glob(path)
    return files_list[random.randint(0, len(files_list))]</code></pre>
</details>
</dd>
<dt id="deep_mri.dataset.dataset.get_train_valid_files"><code class="name flex">
<span>def <span class="ident">get_train_valid_files</span></span>(<span>path='/ADNI/minc_beast/*/*/*.nii', csv_path='/ADNI/ADNI1_Complete_1Yr_1.5T_10_13_2019.csv', train_filter_first_screen=True, valid_filter_first_screen=False, shuffle_strategy=ShuffleStrategy.SHUFFLE_SUBJECTS, valid_train_ratio=0.2, shuffle=False, dropping_group=None, im_id_fnc=&lt;function _get_image_id&gt;, group_folder=-3)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_train_valid_files(path=DEFAULT_PATH,
                          csv_path=DEFAULT_CSV_PATH,
                          train_filter_first_screen=True,
                          valid_filter_first_screen=False,
                          shuffle_strategy=ShuffleStrategy.SHUFFLE_SUBJECTS,
                          valid_train_ratio=0.2,
                          shuffle=False,
                          dropping_group=None,
                          im_id_fnc=_get_image_id,
                          group_folder=-3):
    if dropping_group is not None:
        assert dropping_group in CLASS_NAMES, f&#34;Unknown group to drop {dropping_group}&#34;
    assert isinstance(shuffle_strategy, ShuffleStrategy)

    files_list = glob.glob(path)
    # meta info
    df = pd.read_csv(csv_path)
    df = df.set_index(&#39;Image Data ID&#39;)
    df[&#39;Group&#39;] = df[&#39;Group&#39;].str.lower()
    meta_info = df[[&#39;Visit&#39;, &#39;Group&#39;, &#39;Subject&#39;]].to_dict(&#39;index&#39;)
    if shuffle_strategy == ShuffleStrategy.SHUFFLE_SUBJECTS:
        # Split into groups by subject id
        subjects = {c: [] for c in CLASS_NAMES}
        for f in files_list:
            image_id = int(im_id_fnc(f))
            target = _get_image_group(f, group_folder)
            assert target == meta_info[image_id][&#39;Group&#39;]
            subject = meta_info[image_id][&#39;Subject&#39;]
            visit = meta_info[image_id][&#39;Visit&#39;]
            if visit == 1:
                subjects[target].append(subject)

        # Shuffle
        rnd = random.Random(42)
        if shuffle:
            for group in subjects:
                rnd.shuffle(group)

        # Count groups
        groups_count = np.array([len(subjects[key]) for key in subjects.keys()])
        for count, group in zip(groups_count, subjects.keys()):
            logging.warning(f&#39;{group.upper()} count: {count}&#39;)

        # Split Subjects into train valid groups
        valid_sizes = np.ceil(groups_count * valid_train_ratio).astype(int)
        train_subjects = {key: subjects[key][valid_size:] for key, valid_size in zip(subjects.keys(), valid_sizes)}
        valid_subjects = {key: subjects[key][:valid_size] for key, valid_size in zip(subjects.keys(), valid_sizes)}

        # Groups changed after visits
        train_subjects = _merge_items(train_subjects)
        valid_subjects = _merge_items(valid_subjects)

        train_files = []
        valid_files = []
        for f in files_list:
            image_id = int(im_id_fnc(f))
            target = _get_image_group(f, group_folder)
            assert target == meta_info[image_id][&#39;Group&#39;]
            subject = meta_info[image_id][&#39;Subject&#39;]
            visit = meta_info[image_id][&#39;Visit&#39;]
            # Drop unwanted groups
            if target == dropping_group:
                continue
            if subject in train_subjects:
                if train_filter_first_screen and visit != 1:
                    continue
                train_files.append(f)
            elif subject in valid_subjects:
                if valid_filter_first_screen and visit != 1:
                    continue
                valid_files.append(f)
            else:
                assert visit != 1, &#34;None seen imgs&#34;
                logging.info(f&#34;Image {image_id} without first visit, subject {subject}&#34;)
                if not train_filter_first_screen:
                    logging.info(f&#34;{image_id} appending to train set&#34;)
                    train_files.append(f)

        train_targets = list(map(lambda x: _get_image_group(x, group_folder), train_files))
        valid_targets = list(map(lambda x: _get_image_group(x, group_folder), valid_files))

        return train_files, train_targets, valid_files, valid_targets
    else:
        # Split into groups by subject id
        groups = {c: [] for c in CLASS_NAMES}
        non_first_visit_files = []
        for f in files_list:
            image_id = int(im_id_fnc(f))
            target = _get_image_group(f, group_folder)
            if target == dropping_group:
                continue
            assert target == meta_info[image_id][&#39;Group&#39;]
            visit = meta_info[image_id][&#39;Visit&#39;]
            if (train_filter_first_screen or valid_filter_first_screen) and visit == 1:
                non_first_visit_files.append(f)
            else:
                groups[target].append(f)
        # Shuffle
        rnd = random.Random(42)
        if shuffle:
            for group in groups:
                rnd.shuffle(group)

        # Count groups
        groups_count = np.array([len(groups[key]) for key in groups.keys()])
        for count, group in zip(groups_count, groups.keys()):
            logging.warning(f&#39;{group.upper()} count: {count}&#39;)
        # Split files into train valid groups
        valid_sizes = np.ceil(groups_count * valid_train_ratio).astype(int)
        train_files = {key: groups[key][valid_size:] for key, valid_size in zip(groups.keys(), valid_sizes)}
        valid_files = {key: groups[key][:valid_size] for key, valid_size in zip(groups.keys(), valid_sizes)}

        train_files = _merge_items(train_files)
        valid_files = _merge_items(valid_files)

        if len(non_first_visit_files) &gt; 0:
            logging.warning(f&#39;Filtering non first visit count:{len(non_first_visit_files)}, appending to allowed set&#39;)
            if not train_filter_first_screen:
                train_files = train_files + non_first_visit_files
            if not valid_filter_first_screen:
                valid_files = valid_files + non_first_visit_files

        # Prepare targets
        train_targets = list(map(lambda x: _get_image_group(x, group_folder), train_files))
        valid_targets = list(map(lambda x: _get_image_group(x, group_folder), valid_files))

        return train_files, train_targets, valid_files, valid_targets</code></pre>
</details>
</dd>
<dt id="deep_mri.dataset.dataset.load_files_to_dataset"><code class="name flex">
<span>def <span class="ident">load_files_to_dataset</span></span>(<span>files_list, items_count, generator, **gen_arguments)</span>
</code></dt>
<dd>
<div class="desc"><p>Creating tensorflow dataset from a generator.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>files_list</code></strong> :&ensp;<code>list</code></dt>
<dd>Image file paths</dd>
<dt><strong><code>items_count</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of outputs expected from generator(multiple output from single file)</dd>
<dt><strong><code>generator</code></strong> :&ensp;<code>iterable</code></dt>
<dd>Generator returning the images as tensors</dd>
<dt><strong><code>gen_arguments</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of arguments for the Generator</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.data.Dataset</code></dt>
<dd>Tensorflow dataset of images and desired labels generated by generator</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_files_to_dataset(files_list, items_count, generator, **gen_arguments):
    &#34;&#34;&#34;
    Creating tensorflow dataset from a generator.

    Parameters
    ----------
    files_list : list
        Image file paths
    items_count : int
        Number of outputs expected from generator(multiple output from single file)
    generator : iterable
        Generator returning the images as tensors
    gen_arguments : dict
        Dictionary of arguments for the Generator
    Returns
    -------
    tf.data.Dataset
        Tensorflow dataset of images and desired labels generated by generator
    &#34;&#34;&#34;
    input_arrays = []
    targets = []
    pbar = tqdm(total=items_count)
    gen = generator(files_list=files_list, **gen_arguments)
    for sample, target in gen:
        input_arrays.append(sample)
        targets.append(target)
        pbar.update(1)
    pbar.close()
    return tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(input_arrays), tf.convert_to_tensor(targets)))</code></pre>
</details>
</dd>
<dt id="deep_mri.dataset.dataset.numpy_to_nibabel"><code class="name flex">
<span>def <span class="ident">numpy_to_nibabel</span></span>(<span>numpy_array)</span>
</code></dt>
<dd>
<div class="desc"><p>Transform the numpy array into the <code>nibabel.Image</code> instance.
Parameters</p>
<hr>
<dl>
<dt><strong><code>numpy_array</code></strong> :&ensp;<code>np.array</code></dt>
<dd>3D array</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>nibabel.Image</code></dt>
<dd>Represent each cell of the 3D array as a voxel</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def numpy_to_nibabel(numpy_array):
    &#34;&#34;&#34;
    Transform the numpy array into the `nibabel.Image` instance.
    Parameters
    ----------
    numpy_array: np.array
        3D array
    Returns
    -------
    nibabel.Image
        Represent each cell of the 3D array as a voxel
    &#34;&#34;&#34;
    return Nifti2Image(numpy_array, np.eye(4))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="deep_mri.dataset.dataset.ShuffleStrategy"><code class="flex name class">
<span>class <span class="ident">ShuffleStrategy</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>An enumeration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ShuffleStrategy(Enum):
    SHUFFLE_RANDOM = auto()
    SHUFFLE_SUBJECTS = auto()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="deep_mri.dataset.dataset.ShuffleStrategy.SHUFFLE_RANDOM"><code class="name">var <span class="ident">SHUFFLE_RANDOM</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="deep_mri.dataset.dataset.ShuffleStrategy.SHUFFLE_SUBJECTS"><code class="name">var <span class="ident">SHUFFLE_SUBJECTS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="deep_mri.dataset" href="index.html">deep_mri.dataset</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="deep_mri.dataset.dataset.get_random_img_path" href="#deep_mri.dataset.dataset.get_random_img_path">get_random_img_path</a></code></li>
<li><code><a title="deep_mri.dataset.dataset.get_train_valid_files" href="#deep_mri.dataset.dataset.get_train_valid_files">get_train_valid_files</a></code></li>
<li><code><a title="deep_mri.dataset.dataset.load_files_to_dataset" href="#deep_mri.dataset.dataset.load_files_to_dataset">load_files_to_dataset</a></code></li>
<li><code><a title="deep_mri.dataset.dataset.numpy_to_nibabel" href="#deep_mri.dataset.dataset.numpy_to_nibabel">numpy_to_nibabel</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="deep_mri.dataset.dataset.ShuffleStrategy" href="#deep_mri.dataset.dataset.ShuffleStrategy">ShuffleStrategy</a></code></h4>
<ul class="">
<li><code><a title="deep_mri.dataset.dataset.ShuffleStrategy.SHUFFLE_RANDOM" href="#deep_mri.dataset.dataset.ShuffleStrategy.SHUFFLE_RANDOM">SHUFFLE_RANDOM</a></code></li>
<li><code><a title="deep_mri.dataset.dataset.ShuffleStrategy.SHUFFLE_SUBJECTS" href="#deep_mri.dataset.dataset.ShuffleStrategy.SHUFFLE_SUBJECTS">SHUFFLE_SUBJECTS</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>