{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MCI images 1036, CN images 638, AD images 445\n"
     ]
    }
   ],
   "source": [
    "INPUT_PATH=\"/ADNI/ADNI\"\n",
    "CSV_PATH=\"/ADNI/ADNI1_Complete_1Yr_1.5T_10_13_2019.csv\"\n",
    "OUTPUT_PATH=\"/ADNI/mem_testResource Scheduling\"\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from nipype_ext import *\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "all_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(INPUT_PATH): \n",
    "    for f in filenames: \n",
    "        if f.endswith(\"nii\"): \n",
    "            all_files.append(int(re.split(\"_|\\.\", f)[-2][1:]))\n",
    "all_files = set(all_files)\n",
    "            \n",
    "mci_img_ids = list(set(df.loc[df['Group'] == 'MCI']['Image Data ID'].unique()) & all_files)\n",
    "cn_img_ids = list(set(df.loc[df['Group'] == 'CN']['Image Data ID'].unique())& all_files)\n",
    "ad_img_ids = list(set(df.loc[df['Group'] == 'AD']['Image Data ID'].unique()) & all_files)\n",
    "\n",
    "id_lists = {\n",
    "    \"mci\" : mci_img_ids, \n",
    "    \"cn\"  : cn_img_ids, \n",
    "    \"ad\"  : ad_img_ids\n",
    "}\n",
    "\n",
    "logger.warning(f\"MCI images {len(mci_img_ids)}, CN images {len(cn_img_ids)}, AD images {len(ad_img_ids)}\")\n",
    "\n",
    "import os\n",
    "import nipype.interfaces.io as nio\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "from src.preprocess import RescaleImage\n",
    "from nipype import SelectFiles, Node, Workflow, MapNode, IdentityInterface \n",
    "\n",
    "\n",
    "id_lists[\"test\"] = id_lists['ad'][:10] \n",
    "\n",
    "diagnosis = \"test\"\n",
    "output_dir = os.path.join(OUTPUT_PATH, diagnosis)\n",
    "iterables = id_lists[diagnosis]\n",
    "new_shape = (192, 192, 160)\n",
    "image_format='*_S_*/*/*/S*/*_I{image_id}.nii'\n",
    "input_path = INPUT_PATH\n",
    "\n",
    "\n",
    "# Input\n",
    "iterables = id_lists[diagnosis]\n",
    "infosource = Node(IdentityInterface(fields=['image_id']),\n",
    "                name=\"infosource\")\n",
    "infosource.iterables = [('image_id', iterables)]\n",
    "\n",
    "input_node = Node(SelectFiles({'anat' : image_format},\n",
    "                               base_directory=input_path),\n",
    "                              name=\"input_node\")\n",
    "\n",
    "# Input\n",
    "infosource = Node(IdentityInterface(fields=['image_id']),\n",
    "                name=\"infosource\")\n",
    "infosource.iterables = [('image_id', iterables)]\n",
    "\n",
    "input_node = Node(SelectFiles({'anat' : image_format},\n",
    "                               base_directory=input_path),\n",
    "                              name=\"input_node\")\n",
    "\n",
    "niimnc = Node(Nii2Mnc(), name=\"nii_2_mnc_node\") \n",
    "\n",
    "normalizer = Node(BeastNormalize(), name=\"beast_normalizer_node\")\n",
    "beast = Node(MincBeast(library_dir=\"/opt/minc-1.9.15/share/beast-library-1.1/\"), name=\"beast_node\")\n",
    "product = Node(MincProduct(), name=\"product_node\") \n",
    "\n",
    "mncnii = Node(Mnc2Nii(), name=\"mnc_2_nii_node\")\n",
    "\n",
    "# Sink\n",
    "sink = Node(interface=nio.DataSink(),\n",
    "            name='sink')\n",
    "sink.inputs.regexp_substitutions = [(\"_skullstrip[0-9]+\", \"\")]\n",
    "sink.inputs.base_directory = output_dir\n",
    "\n",
    "# Preprocess Workflow\n",
    "wf = Workflow(name='preproc')\n",
    "\n",
    "# Connections\n",
    "wf.connect(infosource, \"image_id\", input_node, \"image_id\")\n",
    "wf.connect(input_node, \"anat\", niimnc, \"input_file\")\n",
    "wf.connect(niimnc, \"output_file\", normalizer, \"input_file\")\n",
    "wf.connect(normalizer,\"output_file\", beast, \"input_file\")\n",
    "wf.connect(beast, \"output_file\", product, \"mask_file\")\n",
    "wf.connect(normalizer, \"output_file\", product, \"input_file\")\n",
    "wf.connect(product, \"output_file\", mncnii, \"input_file\")\n",
    "wf.connect(mncnii,\"output_file\", sink,\"@out_file\")\n",
    "\n",
    "from nipype.utils.profiler import log_nodes_cb\n",
    "args_dict = {'n_procs' : 2, 'memory_gb' : 10, 'status_callback' : log_nodes_cb}\n",
    "\n",
    "import logging\n",
    "callback_log_path = '/tmp/run_stats.log'\n",
    "logger = logging.getLogger('callback')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.FileHandler(callback_log_path)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "wf.run(plugin='MultiProc', plugin_args=args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nipype_ext.MincBeast at 0x7f4cad7c5f28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beast.interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200430-15:36:58,182 nipype.workflow INFO:\n",
      "\t Workflow preproc settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "200430-15:36:58,888 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "200430-15:36:58,930 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 10 jobs ready. Free memory (GB): 10.00/10.00, Free processors: 2/2.\n",
      "200430-15:36:59,107 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"preproc.input_node\" in \"/tmp/tmpvqojzoik/preproc/_image_id_63538/input_node\".200430-15:36:59,109 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"preproc.input_node\" in \"/tmp/tmpbwqwcy3j/preproc/_image_id_79913/input_node\".\n",
      "\n",
      "200430-15:36:59,121 nipype.workflow INFO:\n",
      "\t [Node] Running \"input_node\" (\"nipype.interfaces.io.SelectFiles\")200430-15:36:59,122 nipype.workflow INFO:\n",
      "\t [Node] Running \"input_node\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "\n",
      "200430-15:37:00,920 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 2 tasks, and 8 jobs ready. Free memory (GB): 9.60/10.00, Free processors: 0/2.\n",
      "                     Currently running:\n",
      "                       * preproc.input_node\n",
      "                       * preproc.input_node\n",
      "200430-15:37:05,36 nipype.workflow INFO:\n",
      "\t [Node] Finished \"preproc.input_node\"."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.utils.draw_gantt_chart import generate_gantt_chart\n",
    "generate_gantt_chart(callback_log_path, cores=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
